<div>
  <h2><strong>Overview</strong></h2>
  <p style="font-size:20px" align="justify">
    The <strong>6th ABC Challenge</strong> is the <strong>Activity Recognition of Nurse Training Activity</strong> using Skelton and Video Dataset with <strong>Generative AI</strong>. Activity types are each task of Endotracheal suctioning.
  </p>
  <ul>
    <li style="font-size:20px" align="justify">The dataset will provide the <strong>skeleton data for training / testing</strong> and the <strong>video data only during the training</strong>.</li>
    <li style="font-size:20px" align="justify">The skeleton data include many samples which recognized <strong>only partial parts of the body due to camera location limitations</strong>.</li>
    <li style="font-size:20px" align="justify">Participants are required to use a <strong>Generative AI</strong> or a <strong>Large Language Model (LLMs)</strong> (hereafter, Generative AI) in a creative way.</li>
  </ul>
  <p style="font-size:20px" align="justify">
    Endotracheal suctioning (ES) is a necessary practice carried out in intensive care units. It involves the removal of pulmonary secretions from a patient with an artificial airway in place. The procedure is associated with complications and risks including bleeding, and infection. Therefore, there is a need to develop an activity recognition system that can ensure the safety of patients as well as reflect to improve their skills while they conduct this complicated procedure. Activity recognition can be used to aid nurses in better managing and increasing the quality of their work, as well as evaluate their performance when they conduct ES. The activity recognition is the initial stage to determine the order of actions and assess the nurse’s skills.
  </p>
  <p style="font-size:20px" align="justify">
    Participants are required to recognize activities based on skeletal data. Since the data collection was a practical experiment, camera locations were limited by not showing the face, the size of the room, etc. Therefore, it is not possible to recognize all of the body parts, and many skeleton data had missing body parts. Additionally, <strong>Generative AI</strong> has been a hot topic in recent years and its momentum will continue to increase. In order to explore the potential for use in the field of activity recognition, participants are required to utilize the <strong>Generative AIs</strong> in a creative way.
  </p>
  
  <h2><strong>Challenge Goal and Task</strong></h2>
  <p style="font-size:20px" align="justify">
    The goal of this challenge is to recognize <strong>9 activities</strong> in Endotracheal suctioning (ES) by using <strong>skeleton data for training / testing</strong> and <strong>video only for training</strong>. In this challenge, participants are required to use a <strong>Generative AIs</strong> in a creative way. For evaluation, we will consider the <strong>F1 score</strong> and the <strong>paper contents</strong>. We will take an average F1 score for all the subjects.
  </p>
  <p style="font-size:20px" align="justify">
    The data we are providing is a part of the dataset used in our previous work, entitled <strong>“Toward Recognizing Nursing Activity in Endotracheal Suctioning Using Video-based Pose Estimation”</strong> <strong>[1]</strong>. The authors of this work proposed an algorithm to define and track the main subject. Also, missing keypoints problems due to the performance of the pose estimation algorithm are improved by smoothing keypoints.
  </p>
  <p style="font-size:18px" align="justify">
    <strong>[1]</strong>
      Hoang Anh Vy Ngo, Quynh N Phuong Vu, Noriyo Colley, Shinji Ninomiya, Satoshi Kanai, Shunsuke Komizunai, Atsushi Konno, Misuzu Nakamura, Sozo Inoue: “Toward Recognizing Nursing Activity in Endotracheal Suctioning Using Video-based Pose Estimation”, The 5th International Conference on Activity and Behavior Computing, 2023, (Germany).
    
  </p>
  <h2><strong>Tutorial webiner</strong></h2>
    <p style="font-size:18px" align="justify">
        As we are going for a more challenging dataset this time in 2024, we are going to organize tutorial webinars on January 17th, 2024 both in Japanese and English. In the webinar, we will cover:
    </p>
    <ul>
        <li style="font-size:20px" align="justify">The explanation of Endotracheal suctioning activity.</li>
        <li style="font-size:20px" align="justify">Give a brief introduction to data processing and baseline, based on a tutorial notebook.</li>
        <li style="font-size:20px" align="justify">Demonstrate how to make the forecast submission file.</li>
    </ul>
    <p style="font-size:18px" align="justify">Tutorial code are probiding as <strong><a href="/tutorial/">google colab, here</a></strong>.</p>
    <p style="font-size:18px" align="justify"><strong>Please register from here: <a href="https://forms.gle/EFnyGWg3f7r8ALLR8">HERE</a></strong></p>
  
  <h2><strong>Important dates</strong></h2>
  <p style="font-size:18px" align="justify">
  This Challenge will be held as part of the <strong><a href="https://abc-research.github.io">ABC Conference 2023</a></strong>
  </p>
  <ul>
    <li style="font-size:20px" align="justify"><strong>Tutorial:</strong> Jan 17, 2024</li>
    <li style="font-size:20px" align="justify"><strong>Challenge opens:</strong> Jan 17, 2024</li>
    <li style="font-size:20px" align="justify"><strong>Test data sent to participants:</strong> Feb 21, 2024</li>
    <li style="font-size:20px" align="justify"><strong>Registration closes:</strong> Mar 6, 2024</li>
    <li style="font-size:20px" align="justify"><strong>Submission of results:</strong> Mar 20, 2024</li>
    <li style="font-size:20px" align="justify"><strong>Submission of paper:</strong> Mar 27, 2024</li>
    <li style="font-size:20px" align="justify"><strong>Review sent to participants:</strong> Apr 10, 2024</li>
    <li style="font-size:20px" align="justify"><strong>Camera-ready papers:</strong> Apr 17, 2024</li>
    <li style="font-size:20px" align="justify"><strong>Conference:</strong> May 29 - 31, 2024</li>
  </ul>
</div>
